import logging
import os
from collections import namedtuple

import numpy as np
import math
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

import zarr
from numcodecs import Blosc

import models
import utils

proj_model_types = {"KCCA": models.KernelLayer}


def project_image(proj_model, filename, output_dir, num_projections, patch_size, workers, batch_size=1):
    logger = logging.getLogger(args.mode + '_log')

    compressor = Blosc(cname='zlib', clevel=9, shuffle=Blosc.BITSHUFFLE)

    num_scales = proj_model.module.num_scales

    # Generate a dataset from a single image to divide in patches and iterate using a dataloader
    histo_ds = utils.ZarrDataset(root=filename, patch_size=patch_size, source_format='zarr')
    data_queue = DataLoader(histo_ds, batch_size=batch_size, num_workers=workers, shuffle=False, pin_memory=True)

    H, W = histo_ds.get_shape()

    group = zarr.group(output_dir, overwrite=True)
    
    proj_patches_group = group.create_group('0', overwrite=True)
    z_patches_proj = proj_patches_group.create_dataset('0', shape=(num_scales, num_projections, int(math.ceil(H/patch_size)), int(math.ceil(W/patch_size))), chunks=(1, num_projections, 1, 1), dtype=np.float32, compressor=compressor)
    
    proj_group = group.create_group('1', overwrite=True)
    z_proj = proj_group.create_dataset('0', fill_value=0, shape=(num_scales, num_projections), chunks=(1, num_projections), dtype=np.float32, compressor=compressor)

    with torch.no_grad():
        for i, (x, _) in enumerate(data_queue):
            y = proj_model(x)
            y = y.cpu().view(batch_size, num_scales, -1).numpy()

            for k, y_k in enumerate(y):
                _, tl_y, tl_x = utils.compute_grid(i*batch_size + k, imgs_shapes=[(H, W)], imgs_sizes=[0, len(histo_ds)], patch_size=patch_size)
                z_patches_proj[..., tl_y, tl_x] = y_k

                z_proj[:] = z_proj[:] + y_k

        z_proj[:] = z_proj[:] / len(histo_ds)

    logger.info('Projected %s into %s successfully ...' % (filename, output_dir))


def setup_network(state):
    """ Setup a simple projection model.

    Parameters
    ----------
    state : Dictionary
        A checkpoint with the fixed projection coefficients.
    
    Returns
    -------
    proj_model : nn.Module
        The projection model implemented by a convolutional neural network

    output_channels : int
        The number of projections generated by this model
    """    
    proj_model_class = proj_model_types.get(state['args']['model_type'], None)
    if proj_model_class is None:
        raise ValueError('Model type %s not supported' % state['args']['model_type'])

    proj_model = proj_model_class(**state['args'])
    proj_model = nn.DataParallel(proj_model)
    
    if os.path.exists(state['args']['trained_model']):
        proj_model.load_state_dict(state['args']['model'])
    else:
        utils.save_state('proj', proj_model.state_dict(), state['args'])

    if state['args']['gpu']:
        proj_model.cuda()

    output_channels = state['args']['num_projections']
    
    return proj_model, output_channels


def project(args):
    """ Compress any supported file format (zarr, or any supported by PIL) into a compressed representation in zarr format.
    """

    # Open checkpoint from trained model state
    state = utils.load_state(args)

    if state is None:
        state = {'args': {}}

    for k in args.__dict__.keys():
        state['args'][k] = args.__dict__[k]
        
    proj_model, output_channels = setup_network(state)

    if args.input[0].lower().endswith('txt'):
        with open(args.input[0], 'r') as f:
            input_fn_list = [l.strip('\n\r') for l in f.readlines()]
    elif not args.input[0].lower().endswith('zarr'):
        # If a directory has been passed, get all image files inside to compress
        input_fn_list = list(map(lambda fn: os.path.join(args.input[0], fn), filter(lambda fn: fn.lower().endswith('zarr'), os.listdir(args.input[0]))))
    else:
        input_fn_list = args.input
        
    output_fn_list = list(map(lambda fn: os.path.join(args.output_dir, fn + '_proj.%s' % 'zarr'), map(lambda fn: os.path.splitext(os.path.basename(fn))[0], input_fn_list)))

    # Segment each file by separate    
    for in_fn, out_fn in zip(input_fn_list, output_fn_list):
        project_image(
            proj_model=proj_model, 
            filename=in_fn,
            output_dir=out_fn,
            num_projections=output_channels,
            patch_size=args.patch_size,
            workers=args.workers,
            batch_size=args.batch_size
            )


if __name__ == '__main__':
    args = utils.get_project_args()
    
    utils.setup_logger(args)
    
    project(args)
    
    logging.shutdown()